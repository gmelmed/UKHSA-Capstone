{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting PDFs into Markdown format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docling\n",
      "  Downloading docling-2.18.0-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/codespace/.local/lib/python3.12/site-packages (from docling) (4.12.3)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /home/codespace/.local/lib/python3.12/site-packages (from docling) (2024.8.30)\n",
      "Collecting deepsearch-glm<2.0.0,>=1.0.0 (from docling)\n",
      "  Downloading deepsearch_glm-1.0.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting docling-core<3.0.0,>=2.17.0 (from docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
      "  Downloading docling_core-2.17.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting docling-ibm-models<4.0.0,>=3.3.0 (from docling)\n",
      "  Downloading docling_ibm_models-3.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting docling-parse<4.0.0,>=3.1.0 (from docling)\n",
      "  Downloading docling_parse-3.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting easyocr<2.0,>=1.7 (from docling)\n",
      "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from docling)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting huggingface_hub<1,>=0.23 (from docling)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting lxml<6.0.0,>=4.0.0 (from docling)\n",
      "  Downloading lxml-5.3.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting marko<3.0.0,>=2.1.2 (from docling)\n",
      "  Downloading marko-2.1.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting openpyxl<4.0.0,>=3.1.5 (from docling)\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in /home/codespace/.local/lib/python3.12/site-packages (from docling) (2.2.3)\n",
      "Collecting pillow<11.0.0,>=10.0.0 (from docling)\n",
      "  Downloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pydantic<3.0.0,>=2.0.0 (from docling)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.3.0 (from docling)\n",
      "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting pypdfium2<5.0.0,>=4.30.0 (from docling)\n",
      "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Collecting python-docx<2.0.0,>=1.1.2 (from docling)\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting python-pptx<2.0.0,>=1.0.2 (from docling)\n",
      "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.2 in /home/codespace/.local/lib/python3.12/site-packages (from docling) (2.32.3)\n",
      "Collecting rtree<2.0.0,>=1.3.0 (from docling)\n",
      "  Downloading Rtree-1.3.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from docling) (1.14.1)\n",
      "Collecting typer<0.13.0,>=0.12.5 (from docling)\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (2.6)\n",
      "Collecting jsonref<2.0.0,>=1.1.0 (from docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
      "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /home/codespace/.local/lib/python3.12/site-packages (from docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling) (4.23.0)\n",
      "Collecting latex2mathml<4.0.0,>=3.77.0 (from docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
      "  Downloading latex2mathml-3.77.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling) (6.0.2)\n",
      "Collecting tabulate<0.10.0,>=0.9.0 (from docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.12.2 in /home/codespace/.local/lib/python3.12/site-packages (from docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling) (4.12.2)\n",
      "Collecting semchunk<3.0.0,>=2.2.0 (from docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
      "  Downloading semchunk-2.2.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
      "  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting jsonlines<4.0.0,>=3.1.0 (from docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading jsonlines-3.1.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.24.4 in /home/codespace/.local/lib/python3.12/site-packages (from docling-ibm-models<4.0.0,>=3.3.0->docling) (2.2.0)\n",
      "Collecting opencv-python-headless<5.0.0.0,>=4.6.0.66 (from docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting safetensors<1,>=0.4.3 (from safetensors[torch]<1,>=0.4.3->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.2.2 in /home/codespace/.local/lib/python3.12/site-packages (from docling-ibm-models<4.0.0,>=3.3.0->docling) (2.5.1+cpu)\n",
      "Collecting torchvision<1,>=0 (from docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading torchvision-0.21.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting tqdm<5.0.0,>=4.64.0 (from docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scikit-image (from easyocr<2.0,>=1.7->docling)\n",
      "  Downloading scikit_image-0.25.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting python-bidi (from easyocr<2.0,>=1.7->docling)\n",
      "  Downloading python_bidi-0.6.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting Shapely (from easyocr<2.0,>=1.7->docling)\n",
      "  Downloading shapely-2.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting pyclipper (from easyocr<2.0,>=1.7->docling)\n",
      "  Downloading pyclipper-1.3.0.post6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting ninja (from easyocr<2.0,>=1.7->docling)\n",
      "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from huggingface_hub<1,>=0.23->docling) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface_hub<1,>=0.23->docling) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface_hub<1,>=0.23->docling) (24.2)\n",
      "Collecting et-xmlfile (from openpyxl<4.0.0,>=3.1.5->docling)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3.0.0,>=2.1.4->docling) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3.0.0,>=2.1.4->docling) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3.0.0,>=2.1.4->docling) (2024.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.0.0->docling)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.0.0->docling)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.3.0->docling)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.2->docling)\n",
      "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.2->docling) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.2->docling) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.2->docling) (2.2.3)\n",
      "Collecting click>=8.0.0 (from typer<0.13.0,>=0.12.5->docling)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<0.13.0,>=0.12.5->docling)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<0.13.0,>=0.12.5->docling)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jsonlines<4.0.0,>=3.1.0->docling-ibm-models<4.0.0,>=3.3.0->docling) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling) (0.22.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->docling) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<0.13.0,>=0.12.5->docling)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich>=10.11.0->typer<0.13.0,>=0.12.5->docling) (2.18.0)\n",
      "Collecting mpire[dill] (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
      "  Downloading mpire-2.10.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (1.3.0)\n",
      "Collecting torch<3.0.0,>=2.2.2 (from docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
      "  Downloading triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image->easyocr<2.0,>=1.7->docling)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->easyocr<2.0,>=1.7->docling)\n",
      "  Downloading tifffile-2025.1.10-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->easyocr<2.0,>=1.7->docling)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.13.0,>=0.12.5->docling)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (3.0.2)\n",
      "Collecting multiprocess>=0.70.15 (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
      "  Downloading multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting dill>=0.3.9 (from multiprocess>=0.70.15->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
      "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Downloading docling-2.18.0-py3-none-any.whl (123 kB)\n",
      "Downloading deepsearch_glm-1.0.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docling_core-2.17.2-py3-none-any.whl (94 kB)\n",
      "Downloading docling_ibm_models-3.3.1-py3-none-any.whl (76 kB)\n",
      "Downloading docling_parse-3.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Downloading lxml-5.3.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marko-2.1.2-py3-none-any.whl (42 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "Downloading Rtree-1.3.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (543 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m543.2/543.2 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
      "Downloading latex2mathml-3.77.0-py3-none-any.whl (73 kB)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "Downloading semchunk-2.2.2-py3-none-any.whl (10 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading torchvision-0.21.0-cp312-cp312-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl (766.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.6/766.6 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "Downloading pyclipper-1.3.0.post6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (963 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.8/963.8 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_bidi-0.6.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n",
      "Downloading scikit_image-0.25.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tifffile-2025.1.10-py3-none-any.whl (227 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading multiprocess-0.70.17-py312-none-any.whl (147 kB)\n",
      "Downloading mpire-2.10.2-py3-none-any.whl (272 kB)\n",
      "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "Installing collected packages: triton, python-bidi, pyclipper, nvidia-cusparselt-cu12, filetype, XlsxWriter, tqdm, tifffile, tabulate, shellingham, Shapely, safetensors, rtree, regex, python-dotenv, pypdfium2, pydantic-core, pillow, opencv-python-headless, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, mdurl, marko, lxml, lazy-loader, latex2mathml, jsonref, jsonlines, et-xmlfile, dill, deepsearch-glm, click, annotated-types, python-pptx, python-docx, pydantic, openpyxl, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, mpire, markdown-it-py, imageio, huggingface_hub, tokenizers, scikit-image, rich, pydantic-settings, nvidia-cusolver-cu12, typer, transformers, torch, semchunk, torchvision, docling-core, easyocr, docling-parse, docling-ibm-models, docling\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.0.0\n",
      "    Uninstalling pillow-11.0.0:\n",
      "      Successfully uninstalled pillow-11.0.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cpu\n",
      "    Uninstalling torch-2.5.1+cpu:\n",
      "      Successfully uninstalled torch-2.5.1+cpu\n",
      "Successfully installed Shapely-2.0.7 XlsxWriter-3.2.2 annotated-types-0.7.0 click-8.1.8 deepsearch-glm-1.0.0 dill-0.3.9 docling-2.18.0 docling-core-2.17.2 docling-ibm-models-3.3.1 docling-parse-3.3.0 easyocr-1.7.2 et-xmlfile-2.0.0 filetype-1.2.0 huggingface_hub-0.28.1 imageio-2.37.0 jsonlines-3.1.0 jsonref-1.1.0 latex2mathml-3.77.0 lazy-loader-0.4 lxml-5.3.0 markdown-it-py-3.0.0 marko-2.1.2 mdurl-0.1.2 mpire-2.10.2 multiprocess-0.70.17 ninja-1.11.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 opencv-python-headless-4.11.0.86 openpyxl-3.1.5 pillow-10.4.0 pyclipper-1.3.0.post6 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-settings-2.7.1 pypdfium2-4.30.1 python-bidi-0.6.3 python-docx-1.1.2 python-dotenv-1.0.1 python-pptx-1.0.2 regex-2024.11.6 rich-13.9.4 rtree-1.3.0 safetensors-0.5.2 scikit-image-0.25.1 semchunk-2.2.2 shellingham-1.5.4 tabulate-0.9.0 tifffile-2025.1.10 tokenizers-0.21.0 torch-2.6.0 torchvision-0.21.0 tqdm-4.67.1 transformers-4.48.2 triton-3.2.0 typer-0.12.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting pymupdf4llm\n",
      "  Downloading pymupdf4llm-0.0.17-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting pymupdf>=1.24.10 (from pymupdf4llm)\n",
      "  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf4llm-0.0.17-py3-none-any.whl (26 kB)\n",
      "Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf, pymupdf4llm\n",
      "Successfully installed pymupdf-1.25.3 pymupdf4llm-0.0.17\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting ocrmypdf\n",
      "  Downloading ocrmypdf-16.8.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting deprecation>=2.1.0 (from ocrmypdf)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting img2pdf>=0.5 (from ocrmypdf)\n",
      "  Downloading img2pdf-0.5.1.tar.gz (104 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20 in /home/codespace/.local/lib/python3.12/site-packages (from ocrmypdf) (24.2)\n",
      "Collecting pdfminer-six>=20220319 (from ocrmypdf)\n",
      "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting pi-heif (from ocrmypdf)\n",
      "  Downloading pi_heif-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting pikepdf>=8.10.1 (from ocrmypdf)\n",
      "  Downloading pikepdf-9.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: pillow>=10.0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from ocrmypdf) (10.4.0)\n",
      "Collecting pluggy>=1 (from ocrmypdf)\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: rich>=13 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from ocrmypdf) (13.9.4)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from pdfminer-six>=20220319->ocrmypdf) (3.4.0)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer-six>=20220319->ocrmypdf)\n",
      "  Using cached cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting Deprecated (from pikepdf>=8.10.1->ocrmypdf)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: lxml>=4.8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pikepdf>=8.10.1->ocrmypdf) (5.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from rich>=13->ocrmypdf) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich>=13->ocrmypdf) (2.18.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/codespace/.local/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer-six>=20220319->ocrmypdf) (1.17.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=13->ocrmypdf) (0.1.2)\n",
      "Collecting wrapt<2,>=1.10 (from Deprecated->pikepdf>=8.10.1->ocrmypdf)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20220319->ocrmypdf) (2.22)\n",
      "Downloading ocrmypdf-16.8.0-py3-none-any.whl (160 kB)\n",
      "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pikepdf-9.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading pi_heif-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Building wheels for collected packages: img2pdf\n",
      "  Building wheel for img2pdf (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for img2pdf: filename=img2pdf-0.5.1-py3-none-any.whl size=49340 sha256=2308f3cec6db56bc5635ff623ea1b5b16afcf630897cde4d8644982aa9b1efd6\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/b8/1b/ed/3cf4c5dbc450803bc57779c6dbe229bb0c69885c12bc557c7c\n",
      "Successfully built img2pdf\n",
      "Installing collected packages: wrapt, pluggy, pi-heif, deprecation, Deprecated, cryptography, pikepdf, pdfminer-six, img2pdf, ocrmypdf\n",
      "Successfully installed Deprecated-1.2.18 cryptography-44.0.0 deprecation-2.1.0 img2pdf-0.5.1 ocrmypdf-16.8.0 pdfminer-six-20240706 pi-heif-0.21.0 pikepdf-9.5.1 pluggy-1.5.0 wrapt-1.17.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting markitdown\n",
      "  Downloading markitdown-0.0.1a3-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/codespace/.local/lib/python3.12/site-packages (from markitdown) (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer in /home/codespace/.local/lib/python3.12/site-packages (from markitdown) (3.4.0)\n",
      "Collecting mammoth (from markitdown)\n",
      "  Downloading mammoth-1.9.0-py2.py3-none-any.whl.metadata (24 kB)\n",
      "Collecting markdownify (from markitdown)\n",
      "  Downloading markdownify-0.14.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from markitdown) (2.2.0)\n",
      "Collecting openai (from markitdown)\n",
      "  Downloading openai-1.61.1-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: openpyxl in /usr/local/python/3.12.1/lib/python3.12/site-packages (from markitdown) (3.1.5)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (from markitdown) (2.2.3)\n",
      "Collecting pathvalidate (from markitdown)\n",
      "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pdfminer-six in /usr/local/python/3.12.1/lib/python3.12/site-packages (from markitdown) (20240706)\n",
      "Collecting puremagic (from markitdown)\n",
      "  Downloading puremagic-1.28-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting pydub (from markitdown)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: python-pptx in /usr/local/python/3.12.1/lib/python3.12/site-packages (from markitdown) (1.0.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from markitdown) (2.32.3)\n",
      "Collecting speechrecognition (from markitdown)\n",
      "  Downloading SpeechRecognition-3.14.1-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting youtube-transcript-api (from markitdown)\n",
      "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4->markitdown) (2.6)\n",
      "Collecting cobble<0.2,>=0.1.3 (from mammoth->markitdown)\n",
      "  Downloading cobble-0.1.4-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: six<2,>=1.15 in /home/codespace/.local/lib/python3.12/site-packages (from markdownify->markitdown) (1.17.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai->markitdown) (4.7.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai->markitdown)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai->markitdown) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai->markitdown)\n",
      "  Downloading jiter-0.8.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai->markitdown) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai->markitdown) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai->markitdown) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/codespace/.local/lib/python3.12/site-packages (from openai->markitdown) (4.12.2)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openpyxl->markitdown) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->markitdown) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->markitdown) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->markitdown) (2024.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pdfminer-six->markitdown) (44.0.0)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from python-pptx->markitdown) (10.4.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from python-pptx->markitdown) (3.2.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from python-pptx->markitdown) (5.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->markitdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->markitdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->markitdown) (2024.8.30)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /home/codespace/.local/lib/python3.12/site-packages (from youtube-transcript-api->markitdown) (0.7.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/codespace/.local/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer-six->markitdown) (1.17.1)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai->markitdown) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->markitdown) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai->markitdown) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai->markitdown) (2.27.2)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six->markitdown) (2.22)\n",
      "Downloading markitdown-0.0.1a3-py3-none-any.whl (16 kB)\n",
      "Downloading mammoth-1.9.0-py2.py3-none-any.whl (52 kB)\n",
      "Downloading markdownify-0.14.1-py3-none-any.whl (11 kB)\n",
      "Downloading openai-1.61.1-py3-none-any.whl (463 kB)\n",
      "Downloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading puremagic-1.28-py3-none-any.whl (43 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading SpeechRecognition-3.14.1-py3-none-any.whl (32.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cobble-0.1.4-py3-none-any.whl (4.0 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.8.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "Installing collected packages: pydub, puremagic, speechrecognition, pathvalidate, jiter, distro, cobble, youtube-transcript-api, markdownify, mammoth, openai, markitdown\n",
      "Successfully installed cobble-0.1.4 distro-1.9.0 jiter-0.8.2 mammoth-1.9.0 markdownify-0.14.1 markitdown-0.0.1a3 openai-1.61.1 pathvalidate-3.2.3 puremagic-1.28 pydub-0.25.1 speechrecognition-3.14.1 youtube-transcript-api-0.6.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install docling\n",
    "%pip install pymupdf4llm\n",
    "%pip install ocrmypdf\n",
    "%pip install markitdown\n",
    "%pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.12/site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pytesseract) (10.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install pytesseract\n",
    "# Run in your terminal the following lines if this package doesn't work\n",
    "# sudo apt-get update\n",
    "# sudo apt-get install tesseract-ocr\n",
    "# sudo apt-get update\n",
    "# sudo apt-get install ghostscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Loading packages\n",
    "import os\n",
    "from docling.document_converter import DocumentConverter\n",
    "import pymupdf4llm\n",
    "import ocrmypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Denmark_2017-07-02.pdf', 'Finland_2017-01-01.pdf', 'Netherlands_2015-06-24.pdf']\n"
     ]
    }
   ],
   "source": [
    "# Sample of countries\n",
    "sample_countries = ['Finland','Netherlands','Denmark'] # [\"Chile\",\"Ecuador\"]\n",
    "\n",
    "# Finding the PDFs related to the sample of countries\n",
    "pdfs = []\n",
    "\n",
    "# Folder with raw PDFs\n",
    "folder_pdfs = \"../data/1-naps-pdfs-raw\"\n",
    "\n",
    "for file in os.listdir(folder_pdfs):\n",
    "    # Checking if any country name from sample_countries is in the file name\n",
    "    if any(country in file for country in sample_countries):\n",
    "        pdfs.append(file)\n",
    "print(pdfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing the PDFs: OCR and conversion to text (TO DO IN TERMINAL. STILL DOESN'T WORK IN PYTHON)\n",
    "# Example in Terminal: # ocrmypdf -l spa Chile_2022-03-09.pdf Chile_2022-03-09_clean.pdf\n",
    "\n",
    "#for pdf in pdfs:\n",
    "    # OCR\n",
    "#    ocrmypdf.ocr(f\"../data/1-naps-pdfs-raw/{pdf}\", f\"../data/2-naps-pdfs-clean/{pdf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Function: Converter\n",
    "converter = DocumentConverter()\n",
    "\n",
    "# Folder to save Markdown files\n",
    "folder_md = \"../data/3-naps-md\"\n",
    "\n",
    "for pdf in pdfs:\n",
    "    # Converting the PDF\n",
    "    result = converter.convert(os.path.join(folder_pdfs, pdf))\n",
    "    \n",
    "    # Exporting the content into markdown format\n",
    "    markdown_content = result.document.export_to_markdown()\n",
    "    \n",
    "    # Constructing the file name\n",
    "    markdown_filename = os.path.splitext(pdf)[0] + '.md'\n",
    "    \n",
    "    # File path\n",
    "    markdown_filepath = os.path.join(folder_md, markdown_filename)\n",
    "    \n",
    "    # Saving\n",
    "    with open(markdown_filepath, 'w') as md_file:\n",
    "        md_file.write(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the PDF\n",
    "result = converter.convert('/Users/giovana/Documents/LSE/PP4B5 Capstone/NAPs_pdf_clean/Chile_2022-03-09_clean_NEW.pdf')\n",
    "    \n",
    "# Exporting the content into markdown format\n",
    "markdown_content = result.document.export_to_markdown()\n",
    "    \n",
    "# Constructing the file name\n",
    "markdown_filename = 'Chile_2022-03-09.txt'\n",
    "    \n",
    "# File path\n",
    "markdown_filepath = os.path.join(folder_md, markdown_filename)\n",
    "    \n",
    "# Saving\n",
    "with open(markdown_filepath, 'w') as md_file:\n",
    "    md_file.write(markdown_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asking OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading packages\n",
    "from openai import OpenAI # OpenAI API\n",
    "import pickle\n",
    "from annoy import AnnoyIndex\n",
    "import json\n",
    "from IPython.display import Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting setting our Open AI client\n",
    "client = OpenAI(\n",
    "    api_key= \"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\"                                   # use your API key here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"country\": \"Chile\",\n",
      "    \"period_start\": 2021,\n",
      "    \"period_end\": 2025\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "document_text = markdown_content\n",
    "\n",
    "prompt = \"\"\"From this National Action Plan, extract the period considered for the National Action Plan and return it in a structured JSON format:\n",
    "1. Country\n",
    "2. Period considered\n",
    "\n",
    "The response **must** follow this exact JSON structure:\n",
    "{\n",
    "    \"country\": \"Name of country as string\",\n",
    "    \"period_start\": \"The year when starts the period as numeric\",\n",
    "    \"period_end\": \"The year when ends the period as numeric\"\n",
    "}\n",
    "\n",
    "National Action Plan:\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format={\"type\":\"json_object\"},\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"\"\"\n",
    "         You are an assistant that extract key information according the questions from National Action Plan on Antimicrobial resistance elaborated by countries. Rely only on the text content.\n",
    "         \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": prompt + document_text},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the JSON response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"country\": \"Chile\",\n",
      "    \"objectives\": [\n",
      "        \"Fortalecer la concientización y la formación respecto a la RAM en la comunidad en general y en grupos específicos.\",\n",
      "        \"Fortalecer el sistema nacional de vigilancia de la resistencia a los antimicrobianos.\",\n",
      "        \"Prevenir y controlar las infecciones asociadas a la salud humana y a la sanidad animal y vegetal.\",\n",
      "        \"Regular y vigilar el uso de los antimicrobianos.\",\n",
      "        \"Mejorar el acceso a la información y fomentar la investigación relacionada con la RAM.\"\n",
      "    ],\n",
      "    \"specific_objectives\": [\n",
      "        \"Desarrollar e implementar estrategias comunicacionales educativas dirigidas a la comunidad.\",\n",
      "        \"Promover en las y los docentes la incorporación de las temáticas de resistencia y uso prudente y responsable de los antimicrobianos en ámbitos educacionales.\",\n",
      "        \"Generar instancias para la creación, actualización y perfeccionamiento de conocimientos y competencias sobre RAM en prescriptores y otros profesionales.\",\n",
      "        \"Generar instancias de capacitación locales para profesionales de la salud en relación con el control de infecciones, el uso de antimicrobianos y la RAM.\",\n",
      "        \"Desarrollar un sistema de vigilancia integrada sobre RAM en microorganismos seleccionados.\",\n",
      "        \"Fortalecer el sistema de monitoreo de Agentes con Resistencia a los Antimicrobianos de Importancia en Salud Pública.\",\n",
      "        \"Fortalecer la vigilancia de la tuberculosis resistente.\",\n",
      "        \"Fortalecer la vigilancia de la resistencia en microorganismos causantes de infecciones de transmisión sexual.\",\n",
      "        \"Prevenir las Infecciones Asociadas a la Atención de Salud (IAAS) y la diseminación de la resistencia antimicrobiana con potencial epidémico en los establecimientos de salud.\",\n",
      "        \"Prevenir las infecciones en ambientes comunitarios.\",\n",
      "        \"Prevenir infecciones producidas por microorganismos específicos.\",\n",
      "        \"Controlar las infecciones en establecimientos de larga estadía para adultos mayores.\",\n",
      "        \"Incorporar medidas regulatorias en relación con la disposición final de residuos que contengan antimicrobianos.\",\n",
      "        \"Prevenir y controlar infecciones en la producción animal.\",\n",
      "        \"Prevenir y controlar infecciones en animales de compañía.\",\n",
      "        \"Prevenir y controlar infecciones en vegetales.\",\n",
      "        \"Regular el uso de antimicrobianos en las personas.\",\n",
      "        \"Fortalecer los instrumentos regulatorios para disminuir el uso de antimicrobianos en animales de producción.\",\n",
      "        \"Regular el uso de antimicrobianos en animales de compañía.\",\n",
      "        \"Regular el uso de antimicrobianos en agricultura.\",\n",
      "        \"Mejorar el acceso a la información sobre RAM.\",\n",
      "        \"Promover la investigación científica y tecnológica en RAM.\",\n",
      "        \"Desarrollar investigación en resistencia de microorganismos específicos.\",\n",
      "        \"Desarrollar investigación sobre microorganismos ambientales en relación a la RAM.\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "document_text = markdown_content\n",
    "\n",
    "prompt = \"\"\"From this National Action Plan (NAP), extract if has any strategic objectives and specific objectives for combating antimicrobial resistance (AMR)? If yes, list all the objectives. Please extract the exact text and return it in a structured JSON format:\n",
    "1. Country\n",
    "2. Strategic objectives\n",
    "3. Specific objectives\n",
    "\n",
    "The response **must** follow this exact JSON structure:\n",
    "{\n",
    "    \"country\": \"Name of country as string\",\n",
    "    \"objectives\": [\"List of strategic objectives as string\"]\n",
    "    \"specific_objectives\": [\"List of specific objectives as string\"]\n",
    "}\n",
    "\n",
    "National Action Plan:\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format={\"type\":\"json_object\"},\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"\"\"\n",
    "         You are an assistant that extract key information according the questions from National Action Plan on Antimicrobial resistance elaborated by countries. Rely only on the text content.\n",
    "         \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": prompt + document_text},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the JSON response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_markdown(md_text, max_chars=3000):\n",
    "    \"\"\"Chunks some markdown by adding new lines until exceeding max_chars.\n",
    "       Each chunk includes the last line of the previous chunk.\"\"\"\n",
    "\n",
    "    lines = md_text.split(\"\\n\")  # Split into lines\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        # Always include the previous line for context\n",
    "        if i > 0 and current_length + len(line) > max_chars:\n",
    "            chunks.append(\"\\n\".join(current_chunk))  # Save the current chunk\n",
    "            current_chunk = [lines[i-1]]  # Start new chunk with the preceding line\n",
    "            current_length = len(lines[i-1])  # Reset length tracker\n",
    "\n",
    "        current_chunk.append(line)\n",
    "        current_length += len(line) + 1  # +1 for the newline character\n",
    "\n",
    "    # Add the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(\"\\n\".join(current_chunk))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_markdown(document_text, max_chars=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................."
     ]
    }
   ],
   "source": [
    "chunks_with_embeddings = []\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\".\", end=\"\")\n",
    "    embedding = get_embedding(chunk)\n",
    "    chunks_with_embeddings.append({\"chunk\": i, \"text\": chunk, \"embedding\": embedding})\n",
    "\n",
    "with open(\"chunks_with_embeddings.pkl\", \"wb\") as f: # it's always good to save the data you've received\n",
    "    pickle.dump(chunks_with_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 20, 3]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Cuál es el periodo de tiempo del plan?\"\n",
    "question_embedding = get_embedding(question)\n",
    "\n",
    "# Define the Annoy index - the index is the data structure that will store the embeddings\n",
    "embedding_dim = len(chunks_with_embeddings[0][\"embedding\"])  # Get vector size\n",
    "annoy_index = AnnoyIndex(embedding_dim, \"angular\")  # Angular distance for similarity\n",
    "\n",
    "# Add chunks to Annoy index\n",
    "for item in chunks_with_embeddings:\n",
    "    annoy_index.add_item(item[\"chunk\"], item[\"embedding\"])\n",
    "\n",
    "# Build the index (the argument is the number of 'trees' - more trees = more accurate but slower)\n",
    "annoy_index.build(10)\n",
    "\n",
    "# Find the most similar chunk to the question\n",
    "n_nearest = 3\n",
    "nearest_chunks = annoy_index.get_nns_by_vector(question_embedding, n_nearest, search_k=-1, include_distances=False)\n",
    "\n",
    "nearest_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"answer_contained\": true,\n",
      "    \"period_start\": 2021,\n",
      "    \"period_end\": 2025,\n",
      "    \"evidence\": \"El Plan Nacional contra la Resistencia a los Antimicrobianos 2021 - 2025 mantiene las mismas lineas estratégicas del plan anterior.\"\n",
      "}\n",
      "```\n",
      "{\n",
      "    \"answer_contained\": true,\n",
      "    \"period_start\": 2021,\n",
      "    \"period_end\": 2025,\n",
      "    \"evidence\": \"Plan Nacional contra la Resistencia a los Antimicrobianos versión 2021-2025.\"\n",
      "}\n",
      "```json\n",
      "{\n",
      "    \"answer_contained\": true,\n",
      "    \"period_start\": 2021,\n",
      "    \"period_end\": 2025,\n",
      "    \"evidence\": \"Lineamientos estratégicos para el periodo 2021- 2025\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant that extract key information according the questions from National Action Plan on Antimicrobial resistance elaborated by countries. Rely only on the text content.\"},\n",
    "    {\"role\": \"user\", \"content\": '''From this part of the National Action Plan, extract the period considered for the National Action Plan and return it in a structured JSON format:\n",
    "1. Country\n",
    "2. Period considered\n",
    "\n",
    "The response **must** follow this exact JSON structure:\n",
    "{\n",
    "    \"answer_contained\": bool, whether the text contains enough information to confidently answer the question,\n",
    "    \"period_start\": \"The year when starts the period as numeric\",\n",
    "    \"period_end\": \"The year when ends the period as numeric\",\n",
    "    \"evidence\": str, a direct quote from the report that supports your answer\n",
    "}'''},\n",
    "]\n",
    "\n",
    "responses = []\n",
    "\n",
    "for i, chunk in enumerate(nearest_chunks):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages + [{\"role\": \"assistant\", \"content\": chunks[chunk]}]\n",
    "    )\n",
    "    print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
