{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting PDFs into Markdown format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install docling\n",
    "!pip install pymupdf4llm\n",
    "!pip install ocrmypdf\n",
    "!pip install markitdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading packages\n",
    "import os\n",
    "from docling.document_converter import DocumentConverter\n",
    "import pymupdf4llm\n",
    "import ocrmypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Finding the PDFs related to the sample of countries\u001b[39;00m\n\u001b[1;32m      5\u001b[0m pdfs \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir():\n\u001b[1;32m      8\u001b[0m     \u001b[39m# Checking if any country name from sample_countries is in the file name\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(country \u001b[39min\u001b[39;00m file \u001b[39mfor\u001b[39;00m country \u001b[39min\u001b[39;00m sample_countries):\n\u001b[1;32m     10\u001b[0m         pdfs\u001b[39m.\u001b[39mappend(file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Sample of countries\n",
    "sample_countries = ['Argentina','Finland','Netherlands']  # ['Ecuador','Denmark','Chile']\n",
    "\n",
    "# Finding the PDFs related to the sample of countries\n",
    "pdfs = []\n",
    "\n",
    "for file in os.listdir():\n",
    "    # Checking if any country name from sample_countries is in the file name\n",
    "    if any(country in file for country in sample_countries):\n",
    "        pdfs.append(file)\n",
    "print(pdfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Converter\n",
    "converter = DocumentConverter()\n",
    "\n",
    "# Folder to save Markdown files\n",
    "folder_md = '/Users/giovana/Documents/LSE/PP4B5 Capstone/NAP_md'\n",
    "\n",
    "for pdf in pdfs:\n",
    "    # Converting the PDF\n",
    "    result = converter.convert(pdf)\n",
    "    \n",
    "    # Exporting the content into markdown format\n",
    "    markdown_content = result.document.export_to_markdown()\n",
    "    \n",
    "    # Constructing the file name\n",
    "    markdown_filename = os.path.splitext(pdf)[0] + '.txt'\n",
    "    \n",
    "    # File path\n",
    "    markdown_filepath = os.path.join(folder_md, markdown_filename)\n",
    "    \n",
    "    # Saving\n",
    "    with open(markdown_filepath, 'w') as md_file:\n",
    "        md_file.write(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ocrmypdf ecuador.pdf ecuador_clean.pdf # (in Terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chile_2022-03-09.pdf...\n",
      "[                                        ] (0/60[                                        ] ( 1/60[=                                       ] ( 2/60[==                                      ] ( 3/60[==                                      ] ( 4/60[===                                     ] ( 5/60[====                                    ] ( 6/60[====                                    ] ( 7/60[=====                                   ] ( 8/[======                                  ] ( 9/60[======                                  ] (10/60[=======                                 ] (11/[========                                ] (12/60[========                                ] (13/60[=========                               ] (14/[==========                              ] (15/60[==========                              ] (16/60[===========                             ] (17/60[============                            ] (18/60[============                            ] (19/60[=============                           ] (20/60[==============                          ] (21/60[==============                          ] (22/60[===============                         ] (23/[================                        ] (24/60[================                        ] (25/60[=================                       ] (26/[==================                      ] (27/60[==================                      ] (28/60[===================                     ] (29/[====================                    ] (30/60[====================                    ] (31/60[=====================                   ] (32/60[======================                  ] (33/60[======================                  ] (34/60[=======================                 ] (35/[========================                ] (36/60[========================                ] (37/60[=========================               ] (38/[==========================              ] (39/60[==========================              ] (40/60[===========================             ] (41/[============================            ] (42/60[============================            ] (43/60[=============================           ] (44/[==============================          ] (45/60[==============================          ] (46/60[===============================         ] (47/[================================        ] (48/60[================================        ] (49/60[=================================       ] (50/[==================================      ] (51/60[==================================      ] (52/60[===================================     ] (53/[====================================    ] (54/60[====================================    ] (55/60[=====================================   ] (56/[======================================  ] (57/60[======================================  ] (58/60[======================================= ] (59/[========================================] (60/60]\n"
     ]
    }
   ],
   "source": [
    "chile_text = pymupdf4llm.to_markdown(\"Chile_2022-03-09.pdf\")\n",
    "\n",
    "markdown_filename = \"Chile_2022-03-09.md\"\n",
    "markdown_filepath = os.path.join(folder_md, markdown_filename)\n",
    "with open(markdown_filepath, \"w\") as f:\n",
    "    f.write(chile_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the PDF\n",
    "result = converter.convert('/Users/giovana/Documents/LSE/PP4B5 Capstone/NAPs_pdf_clean/Chile_2022-03-09_clean_NEW.pdf')\n",
    "    \n",
    "# Exporting the content into markdown format\n",
    "markdown_content = result.document.export_to_markdown()\n",
    "    \n",
    "# Constructing the file name\n",
    "markdown_filename = 'Chile_2022-03-09.txt'\n",
    "    \n",
    "# File path\n",
    "markdown_filepath = os.path.join(folder_md, markdown_filename)\n",
    "    \n",
    "# Saving\n",
    "with open(markdown_filepath, 'w') as md_file:\n",
    "    md_file.write(markdown_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asking OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading packages\n",
    "from openai import OpenAI # OpenAI API\n",
    "import pickle\n",
    "from annoy import AnnoyIndex\n",
    "import json\n",
    "from IPython.display import Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting setting our Open AI client\n",
    "client = OpenAI(\n",
    "    api_key= \"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\"                                   # use your API key here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"country\": \"Chile\",\n",
      "    \"period_start\": 2021,\n",
      "    \"period_end\": 2025\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "document_text = markdown_content\n",
    "\n",
    "prompt = \"\"\"From this National Action Plan, extract the period considered for the National Action Plan and return it in a structured JSON format:\n",
    "1. Country\n",
    "2. Period considered\n",
    "\n",
    "The response **must** follow this exact JSON structure:\n",
    "{\n",
    "    \"country\": \"Name of country as string\",\n",
    "    \"period_start\": \"The year when starts the period as numeric\",\n",
    "    \"period_end\": \"The year when ends the period as numeric\"\n",
    "}\n",
    "\n",
    "National Action Plan:\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format={\"type\":\"json_object\"},\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"\"\"\n",
    "         You are an assistant that extract key information according the questions from National Action Plan on Antimicrobial resistance elaborated by countries. Rely only on the text content.\n",
    "         \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": prompt + document_text},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the JSON response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"country\": \"Chile\",\n",
      "    \"objectives\": [\n",
      "        \"Fortalecer la concientización y la formación respecto a la RAM en la comunidad en general y en grupos específicos.\",\n",
      "        \"Fortalecer el sistema nacional de vigilancia de la resistencia a los antimicrobianos.\",\n",
      "        \"Prevenir y controlar las infecciones asociadas a la salud humana y a la sanidad animal y vegetal.\",\n",
      "        \"Regular y vigilar el uso de los antimicrobianos.\",\n",
      "        \"Mejorar el acceso a la información y fomentar la investigación relacionada con la RAM.\"\n",
      "    ],\n",
      "    \"specific_objectives\": [\n",
      "        \"Desarrollar e implementar estrategias comunicacionales educativas dirigidas a la comunidad.\",\n",
      "        \"Promover en las y los docentes la incorporación de las temáticas de resistencia y uso prudente y responsable de los antimicrobianos en ámbitos educacionales.\",\n",
      "        \"Generar instancias para la creación, actualización y perfeccionamiento de conocimientos y competencias sobre RAM en prescriptores y otros profesionales.\",\n",
      "        \"Generar instancias de capacitación locales para profesionales de la salud en relación con el control de infecciones, el uso de antimicrobianos y la RAM.\",\n",
      "        \"Desarrollar un sistema de vigilancia integrada sobre RAM en microorganismos seleccionados.\",\n",
      "        \"Fortalecer el sistema de monitoreo de Agentes con Resistencia a los Antimicrobianos de Importancia en Salud Pública.\",\n",
      "        \"Fortalecer la vigilancia de la tuberculosis resistente.\",\n",
      "        \"Fortalecer la vigilancia de la resistencia en microorganismos causantes de infecciones de transmisión sexual.\",\n",
      "        \"Prevenir las Infecciones Asociadas a la Atención de Salud (IAAS) y la diseminación de la resistencia antimicrobiana con potencial epidémico en los establecimientos de salud.\",\n",
      "        \"Prevenir las infecciones en ambientes comunitarios.\",\n",
      "        \"Prevenir infecciones producidas por microorganismos específicos.\",\n",
      "        \"Controlar las infecciones en establecimientos de larga estadía para adultos mayores.\",\n",
      "        \"Incorporar medidas regulatorias en relación con la disposición final de residuos que contengan antimicrobianos.\",\n",
      "        \"Prevenir y controlar infecciones en la producción animal.\",\n",
      "        \"Prevenir y controlar infecciones en animales de compañía.\",\n",
      "        \"Prevenir y controlar infecciones en vegetales.\",\n",
      "        \"Regular el uso de antimicrobianos en las personas.\",\n",
      "        \"Fortalecer los instrumentos regulatorios para disminuir el uso de antimicrobianos en animales de producción.\",\n",
      "        \"Regular el uso de antimicrobianos en animales de compañía.\",\n",
      "        \"Regular el uso de antimicrobianos en agricultura.\",\n",
      "        \"Mejorar el acceso a la información sobre RAM.\",\n",
      "        \"Promover la investigación científica y tecnológica en RAM.\",\n",
      "        \"Desarrollar investigación en resistencia de microorganismos específicos.\",\n",
      "        \"Desarrollar investigación sobre microorganismos ambientales en relación a la RAM.\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "document_text = markdown_content\n",
    "\n",
    "prompt = \"\"\"From this National Action Plan (NAP), extract if has any strategic objectives and specific objectives for combating antimicrobial resistance (AMR)? If yes, list all the objectives. Please extract the exact text and return it in a structured JSON format:\n",
    "1. Country\n",
    "2. Strategic objectives\n",
    "3. Specific objectives\n",
    "\n",
    "The response **must** follow this exact JSON structure:\n",
    "{\n",
    "    \"country\": \"Name of country as string\",\n",
    "    \"objectives\": [\"List of strategic objectives as string\"]\n",
    "    \"specific_objectives\": [\"List of specific objectives as string\"]\n",
    "}\n",
    "\n",
    "National Action Plan:\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format={\"type\":\"json_object\"},\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"\"\"\n",
    "         You are an assistant that extract key information according the questions from National Action Plan on Antimicrobial resistance elaborated by countries. Rely only on the text content.\n",
    "         \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": prompt + document_text},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the JSON response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_markdown(md_text, max_chars=3000):\n",
    "    \"\"\"Chunks some markdown by adding new lines until exceeding max_chars.\n",
    "       Each chunk includes the last line of the previous chunk.\"\"\"\n",
    "\n",
    "    lines = md_text.split(\"\\n\")  # Split into lines\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        # Always include the previous line for context\n",
    "        if i > 0 and current_length + len(line) > max_chars:\n",
    "            chunks.append(\"\\n\".join(current_chunk))  # Save the current chunk\n",
    "            current_chunk = [lines[i-1]]  # Start new chunk with the preceding line\n",
    "            current_length = len(lines[i-1])  # Reset length tracker\n",
    "\n",
    "        current_chunk.append(line)\n",
    "        current_length += len(line) + 1  # +1 for the newline character\n",
    "\n",
    "    # Add the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(\"\\n\".join(current_chunk))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_markdown(document_text, max_chars=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................."
     ]
    }
   ],
   "source": [
    "chunks_with_embeddings = []\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\".\", end=\"\")\n",
    "    embedding = get_embedding(chunk)\n",
    "    chunks_with_embeddings.append({\"chunk\": i, \"text\": chunk, \"embedding\": embedding})\n",
    "\n",
    "with open(\"chunks_with_embeddings.pkl\", \"wb\") as f: # it's always good to save the data you've received\n",
    "    pickle.dump(chunks_with_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 20, 3]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Cuál es el periodo de tiempo del plan?\"\n",
    "question_embedding = get_embedding(question)\n",
    "\n",
    "# Define the Annoy index - the index is the data structure that will store the embeddings\n",
    "embedding_dim = len(chunks_with_embeddings[0][\"embedding\"])  # Get vector size\n",
    "annoy_index = AnnoyIndex(embedding_dim, \"angular\")  # Angular distance for similarity\n",
    "\n",
    "# Add chunks to Annoy index\n",
    "for item in chunks_with_embeddings:\n",
    "    annoy_index.add_item(item[\"chunk\"], item[\"embedding\"])\n",
    "\n",
    "# Build the index (the argument is the number of 'trees' - more trees = more accurate but slower)\n",
    "annoy_index.build(10)\n",
    "\n",
    "# Find the most similar chunk to the question\n",
    "n_nearest = 3\n",
    "nearest_chunks = annoy_index.get_nns_by_vector(question_embedding, n_nearest, search_k=-1, include_distances=False)\n",
    "\n",
    "nearest_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"answer_contained\": true,\n",
      "    \"period_start\": 2021,\n",
      "    \"period_end\": 2025,\n",
      "    \"evidence\": \"El Plan Nacional contra la Resistencia a los Antimicrobianos 2021 - 2025 mantiene las mismas lineas estratégicas del plan anterior.\"\n",
      "}\n",
      "```\n",
      "{\n",
      "    \"answer_contained\": true,\n",
      "    \"period_start\": 2021,\n",
      "    \"period_end\": 2025,\n",
      "    \"evidence\": \"Plan Nacional contra la Resistencia a los Antimicrobianos versión 2021-2025.\"\n",
      "}\n",
      "```json\n",
      "{\n",
      "    \"answer_contained\": true,\n",
      "    \"period_start\": 2021,\n",
      "    \"period_end\": 2025,\n",
      "    \"evidence\": \"Lineamientos estratégicos para el periodo 2021- 2025\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant that extract key information according the questions from National Action Plan on Antimicrobial resistance elaborated by countries. Rely only on the text content.\"},\n",
    "    {\"role\": \"user\", \"content\": '''From this part of the National Action Plan, extract the period considered for the National Action Plan and return it in a structured JSON format:\n",
    "1. Country\n",
    "2. Period considered\n",
    "\n",
    "The response **must** follow this exact JSON structure:\n",
    "{\n",
    "    \"answer_contained\": bool, whether the text contains enough information to confidently answer the question,\n",
    "    \"period_start\": \"The year when starts the period as numeric\",\n",
    "    \"period_end\": \"The year when ends the period as numeric\",\n",
    "    \"evidence\": str, a direct quote from the report that supports your answer\n",
    "}'''},\n",
    "]\n",
    "\n",
    "responses = []\n",
    "\n",
    "for i, chunk in enumerate(nearest_chunks):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages + [{\"role\": \"assistant\", \"content\": chunks[chunk]}]\n",
    "    )\n",
    "    print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
